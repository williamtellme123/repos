package com.cloudera.tsexamples

import java.sql.Timestamp
import java.time.{ZoneId, ZonedDateTime}

import breeze.linalg.DenseVector
import com.cloudera.sparkts._
import com.cloudera.sparkts.stats.TimeSeriesStatisticalTests

import org.apache.spark.{SparkContext, SparkConf}
import org.apache.spark.sql.{DataFrame, Row, SQLContext}
import org.apache.spark.sql.types._

/**
 * An example exhibiting the use of TimeSeriesRDD for loading, cleaning, and filtering stock ticker
 * data.
 */
object Stocks {
  /**
   * Creates a Spark DataFrame of (timestamp, symbol, price) from a tab-separated file of stock
   * ticker data.
   */
  def loadObservations(sqlContext: SQLContext, path: String): DataFrame = {
    val rowRdd = sqlContext.sparkContext.textFile(path).map { line =>
      val tokens = line.split('\t')
      val dt = ZonedDateTime.of(tokens(0).toInt, tokens(1).toInt, tokens(2).toInt, 0, 0, 0, 0,
        ZoneId.systemDefault())

      val symbol = tokens(3)
      val price = tokens(4).toDouble
      Row(Timestamp.from(dt.toInstant), symbol, price)
    }
    val fields = Seq(
      StructField("timestamp", TimestampType, true),
      StructField("symbol", StringType, true),
      StructField("price", DoubleType, true)
    )
    val schema = StructType(fields)
    sqlContext.createDataFrame(rowRdd, schema)
  }

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("Spark-TS Ticker Example").setMaster("local")
    conf.set("spark.io.compression.codec", "org.apache.spark.io.LZ4CompressionCodec")
    val sc = new SparkContext(conf)
    val sqlContext = new SQLContext(sc)

    val tickerObs = loadObservations(sqlContext, "../data/ticker.tsv")
    // tickerObs.foreach(println())



    // Create an daily DateTimeIndex over August and September 2015
    val dtIndex = DateTimeIndex.uniformFromInterval(
      ZonedDateTime.parse("2015-08-03"), ZonedDateTime.parse("2015-09-22"),
      new BusinessDayFrequency(1))

    // Align the ticker data on the DateTimeIndex to create a TimeSeriesRDD
    val tickerTsrdd = TimeSeriesRDD.timeSeriesRDDFromObservations(dtIndex, tickerObs,
      "timestamp", "symbol", "price")

    // Cache it in memory
    tickerTsrdd.cache()

    // Count the number of series (number of symbols)
    println(tickerTsrdd.count())

    // Impute missing values using linear interpolation
    val filled = tickerTsrdd.fill("linear")

    // Compute return rates
    val returnRates = filled.returnRates()

    // Compute Durbin-Watson stats for each series
    val dwStats = returnRates.mapValues { x =>
      TimeSeriesStatisticalTests.dwtest(new DenseVector[Double](x.toArray))
    }

    println(dwStats.map(_.swap).min)
    println(dwStats.map(_.swap).max)
  }
}
